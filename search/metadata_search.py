import faiss
import numpy as np

def generate_summary_with_llm(metadata_row, llm_chatbot):
    """
    Generate a new summary for a dataset using the LLM.

    Args:
        metadata_row (pd.Series): A row from the dataframe containing title, summary, and links.
        llm_chatbot (LLMChatbot): An instance of the LLMChatbot class.

    Returns:
        new_summary (str): A new concise summary generated by the LLM.
    """
    metadata_content = (
        f"Title: {metadata_row['title']}\n"
        f"Summary: {metadata_row['summary']}\n"
        f"Links: {metadata_row['links']}\n"
    )

    # Prompt the LLM to generate a concise 1-2 sentence summary
    prompt = (
        f"Based on the following dataset metadata, generate a concise summary in 1-2 sentences that clearly describes the dataset:\n\n"
        f"{metadata_content}\n\n"
        "Please provide a concise summary without additional attributes or key points."
    )

    new_summary = llm_chatbot.generate_response(metadata_content, prompt)
    return new_summary.strip()  # Ensure no extra text or whitespace

def generate_summaries_for_datasets(df, llm_chatbot):
    """
    Generate new summaries for all datasets using the LLM and return a dataframe
    with the metadata summaries and links.

    Args:
        df (pd.DataFrame): The dataframe containing dataset metadata (title, summary, links).
        llm_chatbot (LLMChatbot): The LLMChatbot instance used to generate summaries.

    Returns:
        df_with_summaries (pd.DataFrame): The dataframe with the new 'metadatasummary' and 'links' columns.
    """
    df['metadatasummary'] = df.apply(lambda row: generate_summary_with_llm(row, llm_chatbot), axis=1)
    
    # Keep only the metadata summary and links in the final dataset
    return df[['title', 'metadatasummary', 'links']]    

def query_faiss_index(query, model, metadata_index, k=5):
    """
    Perform a FAISS search to find the top-k most relevant metadata.
    
    Args:
        query (str): The search query.
        model: The SentenceTransformer model used for encoding.
        metadata_index: The FAISS index to search.
        k (int): The number of top results to return.
    
    Returns:
        indices_metadata: Indices of the top k results.
        distances_metadata: Distances of the top k results from the query.
    """
    try:
        # Encode the query into an embedding
        query_embedding = model.encode([query])

        # Perform the FAISS search
        distances, indices = metadata_index.search(np.array(query_embedding), k)

        # Return the top k results
        return indices[0], distances[0]
    except Exception as e:
        print(f"Error querying FAISS index: {e}")
        raise

